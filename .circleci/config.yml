# Use the latest 2.1 version of CircleCI pipeline process engine. See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

orbs:
  win: circleci/windows@2.3.0
  slack: circleci/slack@3.4.2
  kubernetes: circleci/kubernetes@0.11.0
  helm: circleci/helm@1.2.0
  gcloud: circleci/gcp-cli@2.1.0
  queue: eddiewebb/queue@volatile

executors:
  python-36:
    docker:
      - image: python:3.6-slim-buster
  python-37:
    docker:
      - image: python:3.7-slim-buster
  python-38:
    docker:
      - image: python:3.8-slim-buster

parameters:
  det-version:
    type: string
    default: 0.15.3.dev0

release-and-rc-filters: &release-and-rc-filters
  branches:
    ignore:
      - /.*/
  tags:
    only:
      - /(\d)+(\.(\d)+)+/
      - /((\d)+(\.(\d)+)+)(rc)(\d)+/

rc-filters: &rc-filters
  branches:
    ignore:
      - /.*/
  tags:
    only:
      - /((\d)+(\.(\d)+)+)(rc)(\d)+/

release-filters: &release-filters
  branches:
    ignore:
      - /.*/
  tags:
    only:
      - /(\d)+(\.(\d)+)+/

upstream-feature-branch: &upstream-feature-branch
  branches:
    ignore:
      - /pull\/.*/
      - /release-.*/
      - master

commands:
  fix-circle-working-directory:
    description: "Fix CIRCLE_WORKING_DIRECTORY"
    steps:
      - run: echo 'CIRCLE_WORKING_DIRECTORY="${CIRCLE_WORKING_DIRECTORY/#\~/$HOME}"' >> $BASH_ENV

  set-slack-user-id:
    steps:
      - run:
          name: Set Slack variables
          command: |
            if ! [ -x "$(command -v jq)" ]; then
              apt update && apt install -y jq
            fi

            AUTHOR_EMAIL="$(git show -s --format='%ae' $CIRCLE_SHA1)"
            echo "export AUTHOR_EMAIL=\"${AUTHOR_EMAIL}\"" >> $BASH_ENV
            LOOKUP_RESPONSE=$(curl -s "https://slack.com/api/users.lookupByEmail?token=${SLACK_API_TOKEN}&email=${AUTHOR_EMAIL}")
            SUCCESS=$(echo "$LOOKUP_RESPONSE" | jq ".ok")
            if [[ "$SUCCESS" == "true" ]]; then
              SLACK_USER_ID=$(echo "$LOOKUP_RESPONSE" | jq -r ".user.id")
              SLACK_NAME=$(echo "$LOOKUP_RESPONSE" | jq -r ".user.name")
              echo "export SLACK_NAME=\"${SLACK_NAME}\"" >> $BASH_ENV
              echo "export SLACK_USER_ID=\"${SLACK_USER_ID}\"" >> $BASH_ENV
            else
              echo "Unable to find Slack user ID for  \"${AUTHOR_EMAIL}\"."
            fi

  pull-task-images:
    parameters:
      tf1:
        type: boolean
        default: false
      tf2:
        type: boolean
        default: false
    steps:
      - when:
          condition: <<parameters.tf1>>
          steps:
            - run: docker pull determinedai/environments:py-3.7-pytorch-1.7-tf-1.15-cpu-baefbf7
      - when:
          condition: <<parameters.tf2>>
          steps:
            - run: docker pull determinedai/environments:py-3.7-pytorch-1.7-lightning-1.2-tf-2.4-cpu-baefbf7

  login-docker:
    parameters:
      repository:
        type: string
        default: ""
      username:
        type: string
      password:
        type: string
    steps:
      - run: echo "<<parameters.password>>" | docker login <<parameters.repository>> -u "<<parameters.username>>" --password-stdin

  login-helm:
    steps:
      - run: helm repo add determined https://helm.ngc.nvidia.com/isv-ngc-partner/determined --username=$NGC_API_USERNAME --password=$NGC_API_KEY

  install-protoc:
    steps:
      - run: curl -o /tmp/protoc.zip -L https://github.com/protocolbuffers/protobuf/releases/download/v3.12.1/protoc-3.12.1-linux-x86_64.zip
      - run: unzip /tmp/protoc.zip -d $HOME/.local

  setup-go-intg-deps:
    steps:
      - install-protoc # Install newer version of protoc into $HOME/.local/bin, since default is proto2.
      - run: PATH=$HOME/.local/bin:$PATH make -C proto get-deps
      - run: PATH=$HOME/.local/bin:$PATH make -C proto build
      - run: make -C master get-deps
      - run: make -C agent get-deps
      - run: make -C tools start-db

  go-get-deps:
    steps:
      - install-protoc
      - restore_cache:
          keys:
            - det-go-deps-v1dev7-{{ checksum  "master/go.sum" }}-{{ checksum  "agent/go.sum" }}-{{ checksum  "proto/go.sum" }}
      - run: make -C proto get-deps
      - run: make -C master get-deps
      - run: make -C agent get-deps
      - save_cache:
          key: det-go-deps-v1dev7-{{ checksum  "master/go.sum" }}-{{ checksum  "agent/go.sum" }}-{{ checksum  "proto/go.sum" }}
          paths:
            - "/home/circleci/go/pkg/mod/"
  react-get-deps:
    steps:
      - attach_workspace:
          at: .
      - restore_cache:
          keys:
            - det-react-deps-v1dev3-{{ checksum  "webui/react/package-lock.json" }}
      - run:
          name: Get React dependencies
          command: |
            make -C webui/react get-deps-api
            if [ ! -d "webui/react/node_modules" ]; then
              make -C webui/react get-deps-npm
            fi
      - save_cache:
          key: det-react-deps-v1dev3-{{ checksum  "webui/react/package-lock.json" }}
          paths:
            - "webui/react/node_modules"

  install-wheel:
    parameters:
      package-name:
        type: string
      package-location:
        type: string
    steps:
      - run:
          name: Install <<parameters.package-name>>
          working_directory: <<parameters.package-location>>
          command: |
            make build
            pip install --find-links dist <<parameters.package-name>>==<< pipeline.parameters.det-version >>
            pip install --no-deps --force-reinstall --find-links dist <<parameters.package-name>>==<< pipeline.parameters.det-version >>
  setup-python-venv:
    description: Set up and create Python venv.
    parameters:
      determined:
        type: boolean
        default: false
      model-hub: 
        type: boolean
        default: false
      extras-requires:
        type: string
        default: ""
      extra-requirements-file:
        type: string
        default: ""
      executor:
        type: string
    steps:
      - run:
          name: Setup venv
          command: |
            sudo apt-get update
            sudo apt-get install -y python3-venv
            /usr/bin/python3 -m venv /tmp/venv
            echo "export PATH=/tmp/venv/bin:\"${PATH}\"" >> $BASH_ENV
            /tmp/venv/bin/python -m pip install --upgrade pip\<20 wheel setuptools

      - run:
          name: Write cache key
          command: |
            echo <<parameters.executor>> > /tmp/cachefile
            if [ "<<parameters.determined>>" = "true" ]; then
              cat harness/setup.py >> /tmp/cachefile
            fi
            if [ "<<parameters.model-hub>>" = "true" ]; then
              cat model_hub/setup.py >> /tmp/cachefile
            fi
            echo <<parameters.extras-requires>> >> /tmp/cachefile
            if [ -n <<parameters.extra-requirements-file>> ]; then
              cat <<parameters.extra-requirements-file>> >> /tmp/cachefile
            fi

      - restore_cache:
          keys:
            - det-python-deps-v1dev2-{{ checksum "/tmp/cachefile" }}
      - when:
          condition: <<parameters.determined>>
          steps:
            - install-wheel:
                package-name: determined
                package-location: ~/project/harness
      - when:
          condition: <<parameters.model-hub>>
          steps:
            - install-wheel:
                package-name: model-hub
                package-location: ~/project/model_hub
      - run:
          name: Install <<parameters.extras-requires>>
          command: |
            if [ -n "<<parameters.extras-requires>>" ]; then
              pip install <<parameters.extras-requires>>
            fi
      - run:
          name: Install <<parameters.extra-requirements-file>>
          command: |
            if [ -n "<<parameters.extra-requirements-file>>" ]; then
              pip install -r <<parameters.extra-requirements-file>>
            fi
      - save_cache:
          key: det-python-deps-v1dev2-{{ checksum "/tmp/cachefile" }}
          paths:
            - "/tmp/venv"
      - run: python --version
      - run: pip --version
      - run: pip freeze
      # Allow this to fail, but it is useful for debugging.
      - run: sh -c "pip check || true"

  run-e2e-tests:
    parameters:
      mark:
        type: string
        default: ""
      junit-path:
        type: string
        default: "/tmp/test-results/e2e/tests.xml"
      master-scheme:
        type: string
        default: "http"
      master-host:
        type: string
        default: "localhost"
      master-port:
        type: string
        default: "8080"
      master-cert:
        type: string
        default: ""
      master-cert-name:
        type: string
        default: ""
    steps:
      - run:
          name: Split tests
          working_directory: ~/project/e2e_tests
          command: |
            # If a test mark is specified, preselect only files that contain tests with that mark to
            # minimize how wrong CircleCI's splitting can get things.
            if [ -n "<<parameters.mark>>" ]; then
              find tests -name 'test*.py' -print0 | xargs -0 grep -rl 'pytest\.mark\.<<parameters.mark>>'
            else
              circleci tests glob 'tests/**/test*.py'
            fi | circleci tests split --split-by=timings > /tmp/tests-to-run
            echo "Running tests from these files:"
            sed 's/^/- /' </tmp/tests-to-run

      - wait-for-master:
          scheme: <<parameters.master-scheme>>
          host: <<parameters.master-host>>
          port: <<parameters.master-port>>

      - run:
          name: Run e2e tests
          working_directory: ~/project/e2e_tests
          no_output_timeout: 30m
          command: |
            DET_MASTER_CERT_FILE=<<parameters.master-cert>> DET_MASTER_CERT_NAME=<<parameters.master-cert-name>> \
            pytest -vv -s \
            -m '<<parameters.mark>>' \
            --durations=0 \
            --master-scheme="<<parameters.master-scheme>>" \
            --master-host="<<parameters.master-host>>" \
            --master-port="<<parameters.master-port>>" \
            -o junit_family=xunit1 \
            --junit-xml="<<parameters.junit-path>>" \
            $(< /tmp/tests-to-run)

  run-det-deploy-tests:
    parameters:
      mark:
        type: string
        default: ""
      det-version:
        type: string
        default: ""
    steps:
      - run:
          name: Run det-deploy tests
          working_directory: ~/project/e2e_tests
          command: |
            pytest -vv -s \
            -m <<parameters.mark>> \
            --det-version="<<parameters.det-version>>"

  deploy-aws-cluster:
    parameters:
      cluster-id:
        type: string
      det-version:
        type: string
      keypair:
        type: string
        default: "integrations-test"
      enable-cors:
        type: boolean
        default: false
      master-tls-cert:
        type: string
        default: ""
      master-tls-key:
        type: string
        default: ""
      master-cert-name:
        type: string
        default: ""
      cpu-agent-instance-type:
        type: string
        default: "m5.large"
      gpu-agent-instance-type:
        type: string
        default: "p2.xlarge"
      max-dynamic-agents:
        type: integer
        default: 1
      retain-log-group:
        type: boolean
        default: false
      log-group-prefix:
        type: string
        default: ""
    steps:
      - run:
          name: Initialize extra arguments
          command: touch /tmp/det-deploy-extra-args
      - when:
          condition:
            equal:
               [ true, << parameters.enable-cors >> ]
          steps:
          - run:
              name: Enable CORS
              command: 'echo --enable-cors >> /tmp/det-deploy-extra-args'

      - run:
          name: Configure TLS arguments
          command: |
            if [ -n "<<parameters.master-tls-cert>>" ]; then echo "--master-tls-cert <<parameters.master-tls-cert>>" >> /tmp/det-deploy-extra-args; fi
            if [ -n "<<parameters.master-tls-key>>" ]; then echo "--master-tls-key <<parameters.master-tls-key>>" >> /tmp/det-deploy-extra-args; fi
            if [ -n "<<parameters.master-cert-name>>" ]; then echo "--master-cert-name <<parameters.master-cert-name>>" >> /tmp/det-deploy-extra-args; fi
      - run:
          name: Configure log group arguments
          command: |
            if <<parameters.retain-log-group>>; then echo "--retain-log-group" >> /tmp/det-deploy-extra-args; fi
            if [ -n "<<parameters.log-group-prefix>>" ]; then echo "--log-group-prefix <<parameters.log-group-prefix>>" >> /tmp/det-deploy-extra-args; fi
      - run:
          name: Deploy AWS cluster
          command: |
            echo "-----BEGIN ARGS-----"
            cat /tmp/det-deploy-extra-args
            echo "-----END ARGS-----"
            det deploy aws up \
              $(< /tmp/det-deploy-extra-args) \
              --cluster-id <<parameters.cluster-id>> \
              --det-version <<parameters.det-version>> \
              --cpu-agent-instance-type <<parameters.cpu-agent-instance-type>> \
              --gpu-agent-instance-type <<parameters.gpu-agent-instance-type>> \
              --max-dynamic-agents <<parameters.max-dynamic-agents>> \
              --keypair <<parameters.keypair>>
  terminate-aws-cluster:
    parameters:
      cluster-id:
        type: string
    steps:
      - run:
          name: Terminate AWS Cluster
          when: always
          command: |
            det deploy aws down \
              --cluster-id <<parameters.cluster-id>>

  setup-aws-cluster:
    parameters:
      cluster-id:
        type: string
      det-version:
        type: string
      gpu-agent-instance-type:
        type: string
        default: "p2.xlarge"
      cpu-agent-instance-type:
        type: string
        default: "m5.large"
      max-dynamic-agents:
        type: integer
        default: 1
      master-tls-cert:
        type: string
      master-tls-key:
        type: string
      master-cert-name:
        type: string
    steps:
      - set-cluster-id:
          cluster-id: <<parameters.cluster-id>>
      - deploy-aws-cluster:
          cluster-id: ${CLUSTER_ID}
          det-version: <<parameters.det-version>>
          cpu-agent-instance-type: <<parameters.cpu-agent-instance-type>>
          gpu-agent-instance-type: <<parameters.gpu-agent-instance-type>>
          max-dynamic-agents: <<parameters.max-dynamic-agents>>
          master-tls-cert: <<parameters.master-tls-cert>>
          master-tls-key: <<parameters.master-tls-key>>
          master-cert-name: <<parameters.master-cert-name>>
          log-group-prefix: determined-ci
          retain-log-group: true
      - set-master-address-aws:
          cluster-id: ${CLUSTER_ID}
          master-tls-cert: <<parameters.master-tls-cert>>
          master-tls-key: <<parameters.master-tls-key>>

  terminate-gke-cluster:
    parameters:
      cluster-id:
        type: string
      region:
        type: string
    steps:
      # Use a run instead of `gke/delete-cluster` because circle CI orbs do not support `when`.
      - run:
          name: Terminate GKE Cluster
          when: always
          command: |
            gcloud container clusters delete <<parameters.cluster-id>> --quiet --region=<<parameters.region>>

  setup-gke-cluster:
    parameters:
      cluster-id:
        type: string
      det-version:
        type: string
      gke-version:
        type: string
      machine-type:
        type: string
      num-machines:
        type: integer
      gpu-type:
        type: string
      gpus-per-machine:
        type: integer
      region:
        type: string
      node-locations:
        type: string
      gcloud-service-key:
        default: GCLOUD_SERVICE_KEY
        description: The gcloud service key
        type: env_var_name
      google-compute-zone:
        default: GOOGLE_COMPUTE_ZONE
        description: The Google compute zone to connect with via the gcloud CLI
        type: env_var_name
      google-project-id:
        default: GOOGLE_PROJECT_ID
        description: The Google project ID to connect with via the gcloud CLI
        type: env_var_name
    steps:
      - set-cluster-id:
          cluster-id: <<parameters.cluster-id>>
      - gcloud/install:
          version: "319.0.0"
      - kubernetes/install-kubectl
      - gcloud/initialize:
          gcloud-service-key: <<parameters.gcloud-service-key>>
          google-compute-zone: <<parameters.google-compute-zone>>
          google-project-id: <<parameters.google-project-id>>
      - run:
          command: gcloud container clusters create ${CLUSTER_ID} --machine-type=n1-standard-8 --cluster-version=<<parameters.gke-version>> --region=<<parameters.region>> --node-locations=<<parameters.node-locations>> --scopes storage-rw,cloud-platform --num-nodes 1
          name: Create GKE cluster
      - run:
          command: gcloud container node-pools create accel --cluster ${CLUSTER_ID} --region <<parameters.region>> --num-nodes <<parameters.num-machines>> --accelerator type=<<parameters.gpu-type>>,count=<<parameters.gpus-per-machine>> --machine-type=<<parameters.machine-type>> --scopes cloud-platform
          name: Create GPU node pool
      - run:
          command: gcloud container clusters get-credentials ${CLUSTER_ID} --project determined-ai --region <<parameters.region>>
          name: Get Kubeconfig
      - run:
          command: kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded.yaml
          name: Install NVIDIA drivers
      - helm/install-helm-chart:
          chart: helm/charts/determined
          helm-version: v3.2.4
          namespace: "default"
          wait: true
          release-name: "ci"
          values-to-override: |
            detVersion=<<parameters.det-version>>,\
            maxSlotsPerPod=<<parameters.gpus-per-machine>>,\
            checkpointStorage.type=gcs,\
            checkpointStorage.bucket=det-ci
      - set-master-address-gke:
          release-name: "ci"
          namespace: "default"

  setup-gke-cluster-cuda-11:
    parameters:
      cluster-id:
        type: string
      det-version:
        type: string
      gke-version:
        type: string
      machine-type:
        type: string
      num-machines:
        type: integer
      gpu-type:
        type: string
      gpus-per-machine:
        type: integer
      region:
        type: string
      node-locations:
        type: string
      gcloud-service-key:
        default: GCLOUD_SERVICE_KEY
        description: The gcloud service key
        type: env_var_name
      google-compute-zone:
        default: GOOGLE_COMPUTE_ZONE
        description: The Google compute zone to connect with via the gcloud CLI
        type: env_var_name
      google-project-id:
        default: GOOGLE_PROJECT_ID
        description: The Google project ID to connect with via the gcloud CLI
        type: env_var_name
    steps:
      - set-cluster-id:
          cluster-id: <<parameters.cluster-id>>
      - gcloud/install:
          version: "319.0.0"
      - kubernetes/install-kubectl
      - gcloud/initialize:
          gcloud-service-key: <<parameters.gcloud-service-key>>
          google-compute-zone: <<parameters.google-compute-zone>>
          google-project-id: <<parameters.google-project-id>>
      - run:
          command: gcloud container clusters create ${CLUSTER_ID} --machine-type=n1-standard-8 --cluster-version=<<parameters.gke-version>> --region=<<parameters.region>> --node-locations=<<parameters.node-locations>> --scopes storage-rw,cloud-platform --num-nodes 1
          name: Create GKE cluster
      - run:
          command: gcloud container node-pools create accel --cluster ${CLUSTER_ID} --region <<parameters.region>> --num-nodes <<parameters.num-machines>> --accelerator type=<<parameters.gpu-type>>,count=<<parameters.gpus-per-machine>> --machine-type=<<parameters.machine-type>> --scopes cloud-platform
          name: Create GPU node pool
      - run:
          command: gcloud container clusters get-credentials ${CLUSTER_ID} --project determined-ai --region <<parameters.region>>
          name: Get Kubeconfig
      - run:
          command: kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded.yaml
          name: Install NVIDIA drivers
      - run:
          command: kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user "$(gcloud config get-value account)"
          name: Setup cluster role binding
      - helm/install-helm-chart:
          chart: helm/charts/determined
          helm-version: v3.2.4
          namespace: "default"
          wait: true
          release-name: "ci"
          values-to-override: |
            detVersion=<<parameters.det-version>>,\
            maxSlotsPerPod=<<parameters.gpus-per-machine>>,\
            taskContainerDefaults.cpuImage=determinedai/environments:cuda-11.0-pytorch-1.7-lightning-1.2-tf-2.4-gpu-0.13.0,\
            taskContainerDefaults.gpuImage=determinedai/environments:cuda-11.0-pytorch-1.7-lightning-1.2-tf-2.4-gpu-0.13.0,\
            checkpointStorage.type=gcs,\
            checkpointStorage.bucket=det-ci
      - set-master-address-gke:
          release-name: "ci"
          namespace: "default"

  install-webui-test-deps:
    steps:
      - run: |
          . /opt/circleci/.nvm/nvm.sh
          nvm install v12
          nvm alias default v12
          make -C webui/tests get-deps
      - run: docker pull determinedai/gauge-taiko-ts

  setup-local-cluster:
    parameters:
      det-version:
        type: string
    steps:
      - run: det deploy local cluster-up --no-gpu --delete-db --det-version <<parameters.det-version>>

  dump-local-cluster-logs:
    steps:
      - run:
          name: Dump det deploy logs
          when: always
          command: det deploy local logs --no-follow

  run-e2e-webui-tests:
    steps:
      - run: python webui/tests/bin/createUserAndExperiments.py
      - run: |
          mkdir -p webui/tests/reports/logs
          mkdir -p webui/tests/reports/videos
          docker run \
            --name e2e_gauge \
            --network=determined_default \
            --mount type=bind,source=$(pwd)/webui,target=/webui \
            -w /webui/tests \
            --env DET_MASTER=determined-master:8080 \
            determinedai/gauge-taiko-ts
          rm -f webui/tests/reports/videos/*.jpeg

  generate-tls-cert:
    steps:
      - run: |
          .circleci/scripts/generate_cert.sh /tmp/master
          echo 'export MASTER_TLS_CERT=/tmp/master.crt MASTER_TLS_KEY=/tmp/master.key MASTER_CERT_NAME=determined-master-ci' >> $BASH_ENV

  set-master-address-aws:
    parameters:
      cluster-id:
        type: string
      master-tls-cert:
        type: string
      master-tls-key:
        type: string
    steps:
      - run: |
          MASTER_HOST=$(python .circleci/scripts/get_output_from_stack.py <<parameters.cluster-id>> DeterminedAddress)
          echo "export MASTER_HOST=\"${MASTER_HOST}\"" >> $BASH_ENV

      - run: |
          if [ -n "<<parameters.master-tls-cert>>" ] && [ -n "<<parameters.master-tls-key>>" ]; then
            echo "export MASTER_PORT=8443" >> $BASH_ENV
            echo "export MASTER_SCHEME=https" >> $BASH_ENV
          fi

  set-master-address-gke:
    parameters:
      release-name:
        type: string
      namespace:
        type: string
    steps:
      - run:
          name: Set Master Address
          command: |
            MASTER_HOST=$(kubectl get -n <<parameters.namespace>>  service determined-master-service-<<parameters.release-name>> \
            --output jsonpath='{.status.loadBalancer.ingress[0].ip}')
            echo "export MASTER_HOST=\"${MASTER_HOST}\"" >> $BASH_ENV
            echo "${MASTER_HOST}"

  set-google-application-credentials:
    steps:
      - run:
          name: Set Google Application Credentials
          command: |
            GOOGLE_APPLICATION_CREDENTIALS=${HOME}/gcloud-service-key.json
            echo "export GOOGLE_APPLICATION_CREDENTIALS=\"${GOOGLE_APPLICATION_CREDENTIALS}\"" >> $BASH_ENV

  set-cluster-id:
    parameters:
      cluster-id:
        type: string
    steps:
      - run: echo "export CLUSTER_ID=\"<<parameters.cluster-id>>\"" >> $BASH_ENV

  wait-for-master:
    parameters:
      scheme:
        type: string
        default: "http"
      host:
        type: string
      port:
        type: string
        default: "8080"
    steps:
      - run: python .circleci/scripts/wait_for_master.py <<parameters.scheme>>://<<parameters.host>>:<<parameters.port>>

  locate-cloudwatch-logs:
    parameters:
      cluster-id:
        type: string
      region:
        type: string
        default: us-west-2
    steps:
      - run:
          name: Locate CloudWatch logs
          when: always
          command: |
            LOG_GROUP=$(python .circleci/scripts/get_output_from_stack.py <<parameters.cluster-id>> LogGroup)
            echo "Cluster logs can be found in CloudWatch under the log group $LOG_GROUP"
            echo "or the URL below (if the log group is in your default region):"
            ENC_LOG_GROUP=$(echo "$LOG_GROUP" | sed 's|/|$252F|g')
            echo "https://console.aws.amazon.com/cloudwatch/home#logsV2:log-groups/log-group/$ENC_LOG_GROUP"

  pre-package-and-push-system:
    steps:
      - go-get-deps
      - run: make -C proto build
      - run: make -C master check
      - run: make -C agent check


jobs:
  package-and-push-system-local:
    docker:
      - image: cimg/go:1.16
        environment:
          GO111MODULE: "on"
    resource_class: medium+
    steps:
      - checkout
      - attach_workspace:
          at: .
      - setup_remote_docker:
          version: 19.03.12
      - pre-package-and-push-system
      - run: make package
      - run: mkdir -p build/
      - run: docker save -o build/master.image determinedai/determined-master:${CIRCLE_SHA1}
      - run: docker save -o build/agent.image determinedai/determined-agent:${CIRCLE_SHA1}
      - persist_to_workspace:
          root: .
          paths:
            - "master/dist/*linux_amd64.deb"
            - "master/dist/*linux_amd64.rpm"
            - "agent/dist/*linux_amd64.deb"
            - "agent/dist/*linux_amd64.rpm"
            - "build/*.image"

  package-and-push-system-dev:
    docker:
      - image: cimg/go:1.16
        environment:
          GO111MODULE: "on"
    resource_class: medium+
    steps:
      - checkout
      - attach_workspace:
          at: .
      - setup_remote_docker:
          version: 19.03.12
      - login-docker:
          username: ${DOCKER_USER}
          password: ${DOCKER_PASS}
      - pre-package-and-push-system
      - run: make package
      - run: make -C master publish-dev
      - run: make -C agent publish-dev
      - run:
          name: Build and publish model_hub docker images
          command: |
            if [ ${CIRCLE_BRANCH} = 'master' ] || [[ ${CIRCLE_BRANCH} == *"release-"* ]]; then
                # For master and release branches, we will tag and publish both the environment
                # with the git hash as well as the version.  This will make that image available
                # immediately for nightly tests.
                make -C model_hub build-docker
                make -C model_hub publish-docker
            else
                # Otherwise, only tag and publish the environment with the git hash.
                make -C model_hub build-docker-dev
                make -C model_hub publish-docker-dev
            fi

  package-and-push-system-rc:
    docker:
      - image: cimg/go:1.16
        environment:
          GO111MODULE: "on"
    resource_class: medium+
    steps:
      - checkout
      - attach_workspace:
          at: .
      - setup_remote_docker:
          version: 19.03.12
      - login-docker:
          username: ${DOCKER_USER}
          password: ${DOCKER_PASS}
      - login-docker:
          repository: nvcr.io
          username: ${NGC_API_USERNAME}
          password: ${NGC_API_KEY}
      - pre-package-and-push-system
      - run: make package
      - run: make -C master publish
      - run: make -C agent publish
      - run: make -C model_hub build-docker
      - run: make -C model_hub publish-docker

  build-bindings:
    docker:
      - image: cimg/openjdk:14.0.1
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run: make -C bindings get-deps
      - run: make -C bindings build
      - persist_to_workspace:
          root: .
          paths:
            - bindings

  test-e2e-webui:
    machine:
      image: ubuntu-2004:202101-01
    resource_class: large
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run: docker load --input build/master.image
      - run: docker load --input build/agent.image

      - install-webui-test-deps
      - setup-python-venv:
          determined: true
          extra-requirements-file: "webui/tests/requirements.txt"
          executor: ubuntu-2004:202101-01
      - setup-local-cluster:
          det-version: ${CIRCLE_SHA1}
      - run-e2e-webui-tests
      - dump-local-cluster-logs
      - store_test_results:
          path: webui/tests/reports/xml-report/
      - store_artifacts:
          path: webui/tests/reports/

  build-react:
    parameters:
      dev-mode:
        type: boolean
        default: false
    docker:
      - image: cimg/node:12.16
    steps:
      - checkout
      - react-get-deps
      - run: |
            if <<parameters.dev-mode>>; then
              echo 'Setting development mode...'
              export DET_NODE_ENV=development
            fi
            make -C webui/react build
      - persist_to_workspace:
          root: .
          paths:
            - webui/react/build


  build-go:
    docker:
      - image: cimg/go:1.16
        environment:
          GO111MODULE: "on"
    steps:
      - checkout
      - go-get-deps
      - run: make -C proto build
      - run: make -C master build
      - run: make -C agent build
      - persist_to_workspace:
          root: .
          paths:
            - "master/build"
            - "agent/build"

  build-proto:
    docker:
      - image: cimg/go:1.16
        environment:
          GO111MODULE: "on"
    steps:
      - checkout
      - go-get-deps
      - run: make -C proto build
      - persist_to_workspace:
          root: .
          paths:
            - "proto/build/**/*"
  

workflows:
  test-e2e:
    jobs:
      - build-proto
      - build-bindings:
          requires:
            - build-proto
      - build-react:
          dev-mode: true
          requires:
            - build-bindings
      - build-go
      - package-and-push-system-local:
          requires:
            - build-react
      - test-e2e-webui:
          requires:
            - build-bindings
            - package-and-push-system-local
